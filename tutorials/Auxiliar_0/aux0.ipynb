{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W1iISOcrM_SZ"
   },
   "source": [
    "# Markdown\n",
    "\n",
    "Esta es una celda de texto.\n",
    "\n",
    "# Esto es un titulo grandote\n",
    "\n",
    "## Esto es un titulo un poco menos grandote\n",
    "\n",
    "\n",
    "Esto es un parrafo, `esto esta en codigo`, **esto esta en negrita**, *esto esta en cursiva*\n",
    "\n",
    "Se puede insertar codigo multilinea tambien.\n",
    "```java\n",
    "public static void main(String args[]) { \n",
    "    System.out.println(\"wena\");\n",
    "} \n",
    "```\n",
    "\n",
    "\n",
    "Se pueden insertar lineas para separar texto\n",
    "\n",
    "---\n",
    "\n",
    "Se pueden insertar tablas!\n",
    "\n",
    "| Esto      | Es   | Una  | Tabla   | !!      |\n",
    "|-----------|------|------|---------|---------|\n",
    "| 1         | 2    | hola | chao    | un dato |\n",
    "| otro dato | pero | mira | cuantos | datos   |\n",
    "\n",
    "\n",
    "\n",
    "Se puede \"citar\" texto usando cabezas de pescado\n",
    "> Esta es una frase celebre de algun famoso\n",
    ">\n",
    "> -- Albert Einstein\n",
    "\n",
    "Tambien se puede insertar formulas de $\\LaTeX$ dentro del mismo texto: $a = \\frac{e^y\\sqrt{x+2}}{x^2}$. Se puede insertar $\\LaTeX$ en general tambien.\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\it{CE}(p,q)=\\sum_{x}p(x)\\log \\bigg(\\frac{1}{q(x)}\\bigg)=- \\sum_{x}p(x)\\log q(x)\n",
    "\\end{equation}\n",
    "\n",
    "Tambien se puede escribir `html`.\n",
    "\n",
    "<strong> Esto esta en negrita usando html </strong>\n",
    "\n",
    "Aca dejo mas recursos sobre Markdown, Colab y Jupyter Notebook:\n",
    "* https://help.github.com/en/github/writing-on-github/basic-writing-and-formatting-syntax\n",
    "* https://colab.research.google.com/notebooks/intro.ipynb\n",
    "* https://jupyter.org/\n",
    "* https://nbviewer.jupyter.org/github/ipython/ipython/blob/1.x/examples/notebooks/Cell%20Magics.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WXFCSsVL3a31"
   },
   "source": [
    "# Peque√±a introduccion a Numpy y Pandas\n",
    "\n",
    "Colab viene con muchas librerias preinstaldas. Dentro de las que mas vamos a usar estan Numpy y Pandas. Aca tambien dejo unas \"cheat sheets\" para ambas bibliotecas.\n",
    "* https://pandas.pydata.org/docs/\n",
    "* https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf\n",
    "* https://numpy.org/doc/1.18/\n",
    "* https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z2pIg5bq3mVf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eSRuM3bFBHQm",
    "outputId": "93da3a49-9566-4cec-d0e3-f75bccba1f47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "a = list(range(10))\n",
    "a\n",
    "b = []\n",
    "for e in a:\n",
    "    b.append(e**2)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Udj41ExxfDrE"
   },
   "source": [
    "## Numpy\n",
    "Paquete fundamental para computacion matematica.\n",
    "\n",
    "Clase principal: arraglo n-dimensional, ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "y6tLcmKuhiVx",
    "outputId": "01a4a547-a014-45a2-d0c8-3a0fdd8cf662"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9] \n",
      "\n",
      "[ 3  5  7  9 11 13 15 17 19] \n",
      "\n",
      "[1.         1.11111111 1.22222222 1.33333333 1.44444444 1.55555556\n",
      " 1.66666667 1.77777778 1.88888889 2.        ] \n",
      "\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Como crear arreglos\n",
    "\n",
    "# A partir de otro una lista de python\n",
    "print(np.array(range(10)), \"\\n\")\n",
    "\n",
    "# Un arrelo de enteros entre un rango un paso especifico\n",
    "print(np.arange(3, 20, 2), \"\\n\")\n",
    "\n",
    "# Un arreglo con 10 numero entre 1 y 2\n",
    "print(np.linspace(1,2,10), \"\\n\")\n",
    "\n",
    "# Un arreglo de puros 0\n",
    "print(np.zeros(10), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "id": "F1D_DOmBB83t",
    "outputId": "adeffaa8-4987-4b85-f4dd-c9a182857029"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((4,5,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "AWflrWVbiw7b",
    "outputId": "f406b79c-5e1f-4ee3-d839-6ed6d013fcc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]]\n",
      "====================\n",
      "[[[ 0  1  2  3  4]\n",
      "  [ 5  6  7  8  9]\n",
      "  [10 11 12 13 14]\n",
      "  [15 16 17 18 19]]\n",
      "\n",
      " [[20 21 22 23 24]\n",
      "  [25 26 27 28 29]\n",
      "  [30 31 32 33 34]\n",
      "  [35 36 37 38 39]]\n",
      "\n",
      " [[40 41 42 43 44]\n",
      "  [45 46 47 48 49]\n",
      "  [50 51 52 53 54]\n",
      "  [55 56 57 58 59]]]\n"
     ]
    }
   ],
   "source": [
    "# arreglos de mas dimensiones\n",
    "print(np.arange(20).reshape(4,5))\n",
    "print(\"=\" * 20)\n",
    "print(np.arange(60).reshape(3,4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lsxRvWDaiL9_"
   },
   "outputs": [],
   "source": [
    "# Operaciones sobre arreglos\n",
    "a = np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MAn6vVZ0-M7a",
    "outputId": "05c0f747-cca1-4e89-d7b2-b0e1dc6fcea8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  4,  9, 16, 25, 36, 49, 64, 81])"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "XVewYvUz-Stw",
    "outputId": "09114666-8d07-491a-aade-9ea32fb6d0d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 1.        , 1.41421356, 1.73205081, 2.        ,\n",
       "       2.23606798, 2.44948974, 2.64575131, 2.82842712, 3.        ])"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "jCn5Q7Pa-VIx",
    "outputId": "3fa0627b-67a9-4444-91e2-c045e35bc7ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e+00, 3.14159265e+00, 9.86960440e+00, 3.10062767e+01,\n",
       "       9.74090910e+01, 3.06019685e+02, 9.61389194e+02, 3.02029323e+03,\n",
       "       9.48853102e+03, 2.98090993e+04])"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pi**a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "M30GVjFp-Xi5",
    "outputId": "ae99b2ce-458b-46f7-c695-bf12885d6fc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  7,  9, 11, 13, 15, 17, 19, 21, 23])"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.arange(5,15)\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yu5JJELh-bdS",
    "outputId": "17396396-1b8d-46dc-bff9-41ed4918fa98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   6,  14,  24,  36,  50,  66,  84, 104, 126])"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uQawYtDI-daL",
    "outputId": "3c3c0bd3-c101-406a-f2cc-13b10d20fe8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "510"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a @ b.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SKe3EPPKBXX6",
    "outputId": "184c6d2e-490c-4ae5-9110-5cfb1afc9ef9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 22, 38])"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(12).reshape(3,4)\n",
    "a.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "canRRMhyHMC_",
    "outputId": "391f1dbd-b4fb-4f3c-beb5-e356c5e14d11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]]\n"
     ]
    }
   ],
   "source": [
    "# Slicing\n",
    "a = np.arange(12).reshape(3,4)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4tvQzA27HpOj",
    "outputId": "7b2d67bb-1061-419c-feda-6e518e8487e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BI-Rr448HUZ-",
    "outputId": "da8291bd-36b4-459a-d3b7-c45120407704"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 6, 7])"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CdwHTedQHX1m",
    "outputId": "b203eab2-dd6e-4709-c1c8-e294546337ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pq31XS5DHaDd",
    "outputId": "7048f9eb-b620-4652-b91e-85c41d78778a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8, 10])"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2, 0::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gai7XWPNE9yM",
    "outputId": "6b741364-05b6-4d7b-ec19-4c203175ec52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ox0v96zvF1p0",
    "outputId": "393d7425-34e0-48d4-b2a4-fec2071962d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(10)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "fQdS-nGvGAUL",
    "outputId": "44055398-96ec-45ae-ee83-f18dee2024e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "       [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
       "       [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
       "       [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
       "       [50, 51, 52, 53, 54, 55, 56, 57, 58, 59]])"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.arange(10*6).reshape(6,10)\n",
    "b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "6afGxftPGfjZ",
    "outputId": "9c2241d1-711a-47cb-dcd3-1996e05d29f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18],\n",
       "       [10, 12, 14, 16, 18, 20, 22, 24, 26, 28],\n",
       "       [20, 22, 24, 26, 28, 30, 32, 34, 36, 38],\n",
       "       [30, 32, 34, 36, 38, 40, 42, 44, 46, 48],\n",
       "       [40, 42, 44, 46, 48, 50, 52, 54, 56, 58],\n",
       "       [50, 52, 54, 56, 58, 60, 62, 64, 66, 68]])"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b + a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6LaLOoZJ3rUt"
   },
   "source": [
    "## Pandas\n",
    "Una herramienta para hacer analisis y manipulacion de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "colab_type": "code",
    "id": "1RfYSH7R7HCM",
    "outputId": "671dc70d-36ff-42bc-dd41-ecedd877ba19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(200, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_date</th>\n",
       "      <th>publication_hour</th>\n",
       "      <th>author</th>\n",
       "      <th>author_link</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "      <th>embedded_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>10:50</td>\n",
       "      <td>Gonzalo Cifuentes</td>\n",
       "      <td>/lista/autores/gcifuentes</td>\n",
       "      <td>¬øLavar la ropa con luz?: invento de chilenos e...</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/c...</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>Alumnos de Ingenier√≠a de la Universidad Cat√≥...</td>\n",
       "      <td>[#Chile, #Ingenier√≠a UC, #LightWash, #Luz, #Se...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>07:51</td>\n",
       "      <td>Felipe Delgado</td>\n",
       "      <td>/lista/autores/fdelgado</td>\n",
       "      <td>Alrededor de 40 mil hogares de Puente Alto, Pi...</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>Regi√≥n Metropolitana</td>\n",
       "      <td>Alrededor de 40 mil hogares de las comunas d...</td>\n",
       "      <td>[#Pirque, #Puente Alto, #Regi√≥n Metropolitana,...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>08:14</td>\n",
       "      <td>Nicol√°s Parra</td>\n",
       "      <td>/lista/autores/nparra</td>\n",
       "      <td>Habla director de Compin B√≠o B√≠o que se autoap...</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>Regi√≥n del B√≠o B√≠o</td>\n",
       "      <td>Quien fuera el director de la Compin B√≠o B√≠o...</td>\n",
       "      <td>[#Compin, #Concepci√≥n, #Licencia, #Region del ...</td>\n",
       "      <td>[https://media.biobiochile.cl/wp-content/uploa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>08:19</td>\n",
       "      <td>Catalina D√≠az</td>\n",
       "      <td>/lista/autores/catalinadiaz</td>\n",
       "      <td>6 damnificados dej√≥ incendio que destruy√≥ una ...</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>Regi√≥n de los R√≠os</td>\n",
       "      <td>Seis damnificados es el saldo de un incendio...</td>\n",
       "      <td>[#Bomberos, #Damnificados, #Da√±os, #Incendio, ...</td>\n",
       "      <td>[https://media.biobiochile.cl/wp-content/uploa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>08:27</td>\n",
       "      <td>Catalina D√≠az</td>\n",
       "      <td>/lista/autores/catalinadiaz</td>\n",
       "      <td>Con arresto domiciliario qued√≥ menor detenido ...</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>Regi√≥n de los Lagos</td>\n",
       "      <td>Con arresto domiciliario total qued√≥ el adol...</td>\n",
       "      <td>[#Arresto Domiciliario, #Bullying, #Calbuco, #...</td>\n",
       "      <td>[https://media.biobiochile.cl/wp-content/uploa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publication_date publication_hour             author  \\\n",
       "0       05/08/2019            10:50  Gonzalo Cifuentes   \n",
       "1       05/08/2019            07:51     Felipe Delgado   \n",
       "2       05/08/2019            08:14      Nicol√°s Parra   \n",
       "3       05/08/2019            08:19      Catalina D√≠az   \n",
       "4       05/08/2019            08:27      Catalina D√≠az   \n",
       "\n",
       "                   author_link  \\\n",
       "0    /lista/autores/gcifuentes   \n",
       "1      /lista/autores/fdelgado   \n",
       "2        /lista/autores/nparra   \n",
       "3  /lista/autores/catalinadiaz   \n",
       "4  /lista/autores/catalinadiaz   \n",
       "\n",
       "                                               title  \\\n",
       "0  ¬øLavar la ropa con luz?: invento de chilenos e...   \n",
       "1  Alrededor de 40 mil hogares de Puente Alto, Pi...   \n",
       "2  Habla director de Compin B√≠o B√≠o que se autoap...   \n",
       "3  6 damnificados dej√≥ incendio que destruy√≥ una ...   \n",
       "4  Con arresto domiciliario qued√≥ menor detenido ...   \n",
       "\n",
       "                                                link  category  \\\n",
       "0  https://www.biobiochile.cl/noticias/nacional/c...  Nacional   \n",
       "1  https://www.biobiochile.cl/noticias/nacional/r...  Nacional   \n",
       "2  https://www.biobiochile.cl/noticias/nacional/r...  Nacional   \n",
       "3  https://www.biobiochile.cl/noticias/nacional/r...  Nacional   \n",
       "4  https://www.biobiochile.cl/noticias/nacional/r...  Nacional   \n",
       "\n",
       "            subcategory                                            content  \\\n",
       "0              Nacional    Alumnos de Ingenier√≠a de la Universidad Cat√≥...   \n",
       "1  Regi√≥n Metropolitana    Alrededor de 40 mil hogares de las comunas d...   \n",
       "2    Regi√≥n del B√≠o B√≠o    Quien fuera el director de la Compin B√≠o B√≠o...   \n",
       "3    Regi√≥n de los R√≠os    Seis damnificados es el saldo de un incendio...   \n",
       "4   Regi√≥n de los Lagos    Con arresto domiciliario total qued√≥ el adol...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [#Chile, #Ingenier√≠a UC, #LightWash, #Luz, #Se...   \n",
       "1  [#Pirque, #Puente Alto, #Regi√≥n Metropolitana,...   \n",
       "2  [#Compin, #Concepci√≥n, #Licencia, #Region del ...   \n",
       "3  [#Bomberos, #Damnificados, #Da√±os, #Incendio, ...   \n",
       "4  [#Arresto Domiciliario, #Bullying, #Calbuco, #...   \n",
       "\n",
       "                                      embedded_links  \n",
       "0                                                 []  \n",
       "1                                                 []  \n",
       "2  [https://media.biobiochile.cl/wp-content/uploa...  \n",
       "3  [https://media.biobiochile.cl/wp-content/uploa...  \n",
       "4  [https://media.biobiochile.cl/wp-content/uploa...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leer datos en distintos formatos usando las funciones read_*\n",
    "# El objeto principal es el DataFrame\n",
    "dataset = pd.read_json(\n",
    "    'https://github.com/dccuchile/CC6205/releases/download/Data/biobio_nacional.json'\n",
    ")\n",
    "print(type(dataset))\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "GkGqXSmfIlRu",
    "outputId": "71cefacc-7f9c-41b9-b2a5-c3e8d73f9c9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 11 columns):\n",
      "publication_date    200 non-null object\n",
      "publication_hour    200 non-null object\n",
      "author              200 non-null object\n",
      "author_link         200 non-null object\n",
      "title               200 non-null object\n",
      "link                200 non-null object\n",
      "category            200 non-null object\n",
      "subcategory         200 non-null object\n",
      "content             200 non-null object\n",
      "tags                200 non-null object\n",
      "embedded_links      200 non-null object\n",
      "dtypes: object(11)\n",
      "memory usage: 17.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "sz-JV8zs7Jz7",
    "outputId": "3668ac6f-00de-42cb-e84b-29187fb76cfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tipo:  <class 'pandas.core.series.Series'>\n",
      "0    Gonzalo Cifuentes\n",
      "1       Felipe Delgado\n",
      "2        Nicol√°s Parra\n",
      "3        Catalina D√≠az\n",
      "4        Catalina D√≠az\n",
      "Name: author, dtype: object\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "# Obtener toda una columna\n",
    "authors = dataset[\"author\"]\n",
    "print(\"tipo: \", type(authors))\n",
    "print(authors.head())\n",
    "print(authors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "qmmnL_QLOjZs",
    "outputId": "e506303f-64d4-4a0b-f13c-4c21abde9a20"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_date</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>Nacional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>Nacional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>Nacional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>Nacional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>Nacional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publication_date  category\n",
       "0       05/08/2019  Nacional\n",
       "1       05/08/2019  Nacional\n",
       "2       05/08/2019  Nacional\n",
       "3       05/08/2019  Nacional\n",
       "4       05/08/2019  Nacional"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seleccionar multiples columnas\n",
    "dataset[[\"publication_date\", \"category\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "colab_type": "code",
    "id": "vyjRofIjO0RH",
    "outputId": "79aac8da-deb1-4d4c-ceae-e8a0d3c418b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     True\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "Name: subcategory, dtype: bool \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_date</th>\n",
       "      <th>publication_hour</th>\n",
       "      <th>author</th>\n",
       "      <th>author_link</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "      <th>embedded_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>10:50</td>\n",
       "      <td>Gonzalo Cifuentes</td>\n",
       "      <td>/lista/autores/gcifuentes</td>\n",
       "      <td>¬øLavar la ropa con luz?: invento de chilenos e...</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/c...</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>Alumnos de Ingenier√≠a de la Universidad Cat√≥...</td>\n",
       "      <td>[#Chile, #Ingenier√≠a UC, #LightWash, #Luz, #Se...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>08:44</td>\n",
       "      <td>Emilio Lara</td>\n",
       "      <td>/lista/autores/elara</td>\n",
       "      <td>Crisis interna del PS gatilla renuncia de 291 ...</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/c...</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>291 militantes renunciaron al Partido Social...</td>\n",
       "      <td>[#Narcotr√°fico, #Partido Socialista, #PS, #Ser...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>09:50</td>\n",
       "      <td>Emilio Lara</td>\n",
       "      <td>/lista/autores/elara</td>\n",
       "      <td>Cadem: Pi√±era mantiene aprobaci√≥n y reducci√≥n ...</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/c...</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>Los √∫ltimos resultados de la Encuesta Cadem ...</td>\n",
       "      <td>[#Cadem, #Gabinete, #Gobierno, #jornada labora...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>10:30</td>\n",
       "      <td>Emilio Lara</td>\n",
       "      <td>/lista/autores/elara</td>\n",
       "      <td>Senado podr√≠a votar esta semana extensi√≥n de g...</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/c...</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>Esta semana, luego de un a√±o y cuatro meses ...</td>\n",
       "      <td>[#CFT, #Educaci√≥n, #Gobierno, #Gratuidad, #IP]</td>\n",
       "      <td>[https://media.biobiochile.cl/wp-content/uploa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>05/08/2019</td>\n",
       "      <td>05:30</td>\n",
       "      <td>Manuel Stuardo</td>\n",
       "      <td>/lista/autores/mstuardo</td>\n",
       "      <td>Comisi√≥n del Trabajo votar√° este martes petici...</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/c...</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>Nacional</td>\n",
       "      <td>La comisi√≥n de Trabajo de la C√°mara votar√° e...</td>\n",
       "      <td>[#Comisi√≥n del Trabajo, #Frente Amplio, #Gael ...</td>\n",
       "      <td>[https://media.biobiochile.cl/wp-content/uploa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publication_date  ...                                     embedded_links\n",
       "0        05/08/2019  ...                                                 []\n",
       "6        05/08/2019  ...                                                 []\n",
       "11       05/08/2019  ...                                                 []\n",
       "14       05/08/2019  ...  [https://media.biobiochile.cl/wp-content/uploa...\n",
       "16       05/08/2019  ...  [https://media.biobiochile.cl/wp-content/uploa...\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seleccionar subconjunto de filas\n",
    "mask = dataset[\"subcategory\"] == \"Nacional\"\n",
    "print(mask.head(), \"\\n\")\n",
    "\n",
    "dataset[mask].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 739
    },
    "colab_type": "code",
    "id": "jl2pbVeQCP2p",
    "outputId": "6a033403-a4f8-4d70-f968-99c1d1527873"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Catalina D√≠az</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Nicol√°s D√≠az</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Mar√≠a Jos√© Villarroel</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Sandar Oporto</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Sandar Oporto</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Mat√≠as Vega</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Mar√≠a Jos√© Villarroel</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Nicol√°s Parra</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Mat√≠as Vega</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Valentina Gonz√°lez</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Valentina Gonz√°lez</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Manuel Stuardo</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Yessenia M√°rquez</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Yessenia M√°rquez</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Manuel Stuardo</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Nicol√°s D√≠az</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Manuel Stuardo</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Yessenia M√°rquez</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Yessenia M√°rquez</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Valentina Gonz√°lez</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Nicol√°s Parra</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Mat√≠as Vega</td>\n",
       "      <td>https://www.biobiochile.cl/noticias/nacional/r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    author                                               link\n",
       "4            Catalina D√≠az  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "22            Nicol√°s D√≠az  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "50   Mar√≠a Jos√© Villarroel  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "55           Sandar Oporto  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "59           Sandar Oporto  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "63             Mat√≠as Vega  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "76   Mar√≠a Jos√© Villarroel  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "82           Nicol√°s Parra  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "89             Mat√≠as Vega  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "105     Valentina Gonz√°lez  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "124     Valentina Gonz√°lez  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "128         Manuel Stuardo  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "131       Yessenia M√°rquez  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "143       Yessenia M√°rquez  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "152         Manuel Stuardo  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "154           Nicol√°s D√≠az  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "157         Manuel Stuardo  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "169       Yessenia M√°rquez  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "184       Yessenia M√°rquez  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "190     Valentina Gonz√°lez  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "191          Nicol√°s Parra  https://www.biobiochile.cl/noticias/nacional/r...\n",
       "195            Mat√≠as Vega  https://www.biobiochile.cl/noticias/nacional/r..."
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loc/iloc, loc on labels, iloc con indices\n",
    "dataset.loc[dataset[\"subcategory\"] == \"Regi√≥n de los Lagos\", [\"author\", \"link\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "B69dWpTgSyUI",
    "outputId": "12b06302-7c50-43b7-8c9a-e54c4f0dc0ef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_hour</th>\n",
       "      <th>author_link</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>00:57</td>\n",
       "      <td>/lista/autores/ndiaz</td>\n",
       "      <td>Detienen a conductor en Coronel tras ofrecer $...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>21:33</td>\n",
       "      <td>/lista/autores/ndiaz</td>\n",
       "      <td>Puerto Montt implementar√° plan de contingencia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>22:00</td>\n",
       "      <td>/lista/autores/mstuardo</td>\n",
       "      <td>Ma√±alich y Comisi√≥n de Salud analizar√°n este l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>23:16</td>\n",
       "      <td>/lista/autores/mstuardo</td>\n",
       "      <td>En prisi√≥n preventiva queda exfuncionario de l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>23:49</td>\n",
       "      <td>/lista/autores/mstuardo</td>\n",
       "      <td>Autom√≥vil y bus del Transantiago protagonizan ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publication_hour  ...                                              title\n",
       "20            00:57  ...  Detienen a conductor en Coronel tras ofrecer $...\n",
       "22            21:33  ...  Puerto Montt implementar√° plan de contingencia...\n",
       "24            22:00  ...  Ma√±alich y Comisi√≥n de Salud analizar√°n este l...\n",
       "26            23:16  ...  En prisi√≥n preventiva queda exfuncionario de l...\n",
       "28            23:49  ...  Autom√≥vil y bus del Transantiago protagonizan ...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[20:30:2, [1, 3, 4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y2h9oxU-zxhy"
   },
   "source": [
    "# NLTK\n",
    "NLTK (Natural Language Processing Kit) es una libreria de procesamiento de lenguaje natural. Ofrece utilidades como tokenizacion, lemmatization, stemming,etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BrivNfAazxPC",
    "outputId": "57b53aa8-5768-4b78-905d-542244abce33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "-OA5cQxt1Z1J",
    "outputId": "96b59bd6-be8c-4102-a2f8-29b6f24431b3"
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/spanish.pickle\u001b[0m\n\n  Searched in:\n    - '/home/fbravo/nltk_data'\n    - '/home/fbravo/anaconda3/nltk_data'\n    - '/home/fbravo/anaconda3/share/nltk_data'\n    - '/home/fbravo/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14945/1344243556.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Hola como est√°n, esta es una frase en espa√±ol.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"spanish\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     return [\n\u001b[1;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tokenizers/punkt/{language}.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nltk\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/spanish.pickle\u001b[0m\n\n  Searched in:\n    - '/home/fbravo/nltk_data'\n    - '/home/fbravo/anaconda3/nltk_data'\n    - '/home/fbravo/anaconda3/share/nltk_data'\n    - '/home/fbravo/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# tokenizacion\n",
    "from nltk import word_tokenize\n",
    "s = \"Hola como est√°n, esta es una frase en espa√±ol.\"\n",
    "\n",
    "word_tokenize(s, language=\"spanish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "6Gi5BRJ21gka",
    "outputId": "1d86ade8-ac4a-4d45-e5a1-973115c6ea4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stemming\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"spanish\")\n",
    "print(stemmer.stem(\"perros\"))\n",
    "stemmer.stem(\"perros\") == stemmer.stem(\"perro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "kihbH9Qf3BBd",
    "outputId": "b7f31066-069d-44b1-c06c-7d86a83fb9e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hous\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/home/fbravo/nltk_data'\n    - '/home/fbravo/anaconda3/nltk_data'\n    - '/home/fbravo/anaconda3/share/nltk_data'\n    - '/home/fbravo/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - '/home/fbravo/nltk_data'\n    - '/home/fbravo/anaconda3/nltk_data'\n    - '/home/fbravo/anaconda3/share/nltk_data'\n    - '/home/fbravo/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14945/3410536651.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mwnl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwnl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"houses\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/stem/wordnet.py\u001b[0m in \u001b[0;36mlemmatize\u001b[0;34m(self, word, pos)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mlemma\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mword\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \"\"\"\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mlemmas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{self.__name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/home/fbravo/nltk_data'\n    - '/home/fbravo/anaconda3/nltk_data'\n    - '/home/fbravo/anaconda3/share/nltk_data'\n    - '/home/fbravo/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# lemmatization, no pille lemmatizer de nltk en espannol\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "print(stemmer.stem(\"houses\"))\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "print(wnl.lemmatize(\"houses\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bhC7n-30cWU0"
   },
   "source": [
    "# Datos\n",
    "Aca voy a mostrar como acceder a datos desde colab.\n",
    "\n",
    "\n",
    "Una forma super simple es conectarse a su Drive y desde ahi acceder a los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "33o_iAbLaX7B",
    "outputId": "7c5b45e1-b88b-4954-ad43-0d831fb85610"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Esto no corre en local\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "47sC1htba_63",
    "outputId": "0468ac81-aee5-4b9d-cdbd-62047a21ab0c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idNoticia</th>\n",
       "      <th>idComment</th>\n",
       "      <th>creatorId</th>\n",
       "      <th>parentId</th>\n",
       "      <th>banned</th>\n",
       "      <th>authSource</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>denounces</th>\n",
       "      <th>time</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892722</td>\n",
       "      <td>4799147</td>\n",
       "      <td>160736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>facebook</td>\n",
       "      <td>&amp;nbsp;Muy bueno lo que vi del frstival</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1516963115000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892722</td>\n",
       "      <td>4798886</td>\n",
       "      <td>7823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>facebook</td>\n",
       "      <td>&amp;nbsp;Improvisando y con cero libreto..ajiaj e...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1516960895000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>892722</td>\n",
       "      <td>4798914</td>\n",
       "      <td>245784</td>\n",
       "      <td>4798886.0</td>\n",
       "      <td>False</td>\n",
       "      <td>facebook</td>\n",
       "      <td>&amp;nbsp;@Rodrigo Cancino Sandoval[7823]&amp;nbsp;ese...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1516961099000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>892722</td>\n",
       "      <td>4798783</td>\n",
       "      <td>65076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>facebook</td>\n",
       "      <td>&amp;nbsp;Avello es un adelantado, genial&amp;nbsp;</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1516959790000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>892722</td>\n",
       "      <td>4798175</td>\n",
       "      <td>11263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>facebook</td>\n",
       "      <td>&amp;nbsp;Su humor improvisado me pareci√≥ genial y...</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1516951826000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idNoticia  idComment  creatorId  ...  denounces           time level\n",
       "0     892722    4799147     160736  ...          0  1516963115000     0\n",
       "1     892722    4798886       7823  ...          0  1516960895000     0\n",
       "2     892722    4798914     245784  ...          0  1516961099000     1\n",
       "3     892722    4798783      65076  ...          0  1516959790000     0\n",
       "4     892722    4798175      11263  ...          0  1516951826000     0\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"drive/My Drive/2018_emol_comments_small.tsv\", delimiter=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "muRycP3gctPW"
   },
   "source": [
    "Usando la habilidad de colab de ejecutar comandos de shell desde una celda de codigo, podemos descargar un dataset usando la linea de comando, ya sea con `wget` o `curl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "id": "8L259tX3eu8v",
    "outputId": "36db9012-da19-4cd6-8dd1-24d49285bc05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-26 18:53:44--  http://users.dcc.uchile.cl/~gchapero/datasets/2018_emol_comments_small.tsv\n",
      "Resolving users.dcc.uchile.cl (users.dcc.uchile.cl)... 200.9.99.211, 192.80.24.4\n",
      "Connecting to users.dcc.uchile.cl (users.dcc.uchile.cl)|200.9.99.211|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://users.dcc.uchile.cl/~gchapero/datasets/2018_emol_comments_small.tsv [following]\n",
      "--2020-03-26 18:53:44--  https://users.dcc.uchile.cl/~gchapero/datasets/2018_emol_comments_small.tsv\n",
      "Connecting to users.dcc.uchile.cl (users.dcc.uchile.cl)|200.9.99.211|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11115406 (11M) [text/tab-separated-values]\n",
      "Saving to: ‚Äò2018_emol_comments_small.tsv‚Äô\n",
      "\n",
      "2018_emol_comments_ 100%[===================>]  10.60M  4.67MB/s    in 2.3s    \n",
      "\n",
      "2020-03-26 18:53:47 (4.67 MB/s) - ‚Äò2018_emol_comments_small.tsv‚Äô saved [11115406/11115406]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget users.dcc.uchile.cl/~gchapero/datasets/2018_emol_comments_small.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "colab_type": "code",
    "id": "ICb_o2_qdAtt",
    "outputId": "02e796b5-9552-4347-b505-9254820ab2ad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idNoticia</th>\n",
       "      <th>idComment</th>\n",
       "      <th>creatorId</th>\n",
       "      <th>parentId</th>\n",
       "      <th>banned</th>\n",
       "      <th>authSource</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>denounces</th>\n",
       "      <th>time</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892722</td>\n",
       "      <td>4799147</td>\n",
       "      <td>160736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>facebook</td>\n",
       "      <td>&amp;nbsp;Muy bueno lo que vi del frstival</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1516963115000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892722</td>\n",
       "      <td>4798886</td>\n",
       "      <td>7823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>facebook</td>\n",
       "      <td>&amp;nbsp;Improvisando y con cero libreto..ajiaj e...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1516960895000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>892722</td>\n",
       "      <td>4798914</td>\n",
       "      <td>245784</td>\n",
       "      <td>4798886.0</td>\n",
       "      <td>False</td>\n",
       "      <td>facebook</td>\n",
       "      <td>&amp;nbsp;@Rodrigo Cancino Sandoval[7823]&amp;nbsp;ese...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1516961099000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>892722</td>\n",
       "      <td>4798783</td>\n",
       "      <td>65076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>facebook</td>\n",
       "      <td>&amp;nbsp;Avello es un adelantado, genial&amp;nbsp;</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1516959790000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>892722</td>\n",
       "      <td>4798175</td>\n",
       "      <td>11263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>facebook</td>\n",
       "      <td>&amp;nbsp;Su humor improvisado me pareci√≥ genial y...</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1516951826000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idNoticia  idComment  creatorId  ...  denounces           time level\n",
       "0     892722    4799147     160736  ...          0  1516963115000     0\n",
       "1     892722    4798886       7823  ...          0  1516960895000     0\n",
       "2     892722    4798914     245784  ...          0  1516961099000     1\n",
       "3     892722    4798783      65076  ...          0  1516959790000     0\n",
       "4     892722    4798175      11263  ...          0  1516951826000     0\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"2018_emol_comments_small.tsv\", delimiter=\"\\t\")\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "aux0.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
